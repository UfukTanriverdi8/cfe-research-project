{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6f079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f6301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1266 questions\n"
     ]
    }
   ],
   "source": [
    "# Path to your PlausibleQA sample dataset\n",
    "DATA_PATH = './data/random_test_data/verified_w_candidates_from_3000.json'\n",
    "OUTPUT_DIR = \"./data/advanced/\"\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Load once\n",
    "data = load_data(DATA_PATH)\n",
    "print(f\"Loaded {len(data)} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53563d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CJK_RE = re.compile(r'[\\u4E00-\\u9FFF]')\n",
    "EMOJI_RE = re.compile(\n",
    "    '['\n",
    "    '\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "    '\\U0001F600-\\U0001F64F'  # emoticons\n",
    "    '\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "    '\\U0001F700-\\U0001F77F'  # alchemical symbols\n",
    "    '\\U0001F780-\\U0001F7FF'  # geometric shapes extended\n",
    "    '\\U0001F800-\\U0001F8FF'  # supplemental arrows-C\n",
    "    ']'\n",
    ")\n",
    "# Matches *any* non-ASCII byte\n",
    "NON_ASCII_RE = re.compile(r'[^\\x00-\\x7F]')\n",
    "\n",
    "def is_valid_answer(ans: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns False if ans:\n",
    "      - is not a non-empty str\n",
    "      - contains any CJK character\n",
    "      - contains any emoji\n",
    "      - contains any non-ASCII character\n",
    "    \"\"\"\n",
    "    if not isinstance(ans, str) or not ans.strip():\n",
    "        return False\n",
    "    if CJK_RE.search(ans):\n",
    "        return False\n",
    "    if EMOJI_RE.search(ans):\n",
    "        return False\n",
    "    if NON_ASCII_RE.search(ans):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea7ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(candidate_answers):\n",
    "    \"\"\"Normalize raw listwise scores so they sum to 1.\"\"\" \n",
    "    raw = [info['listwise'] for info in candidate_answers.values()]\n",
    "    total = sum(raw)\n",
    "    return [s/total if total>0 else 0 for s in raw]\n",
    "\n",
    "def compute_entropy(probs):\n",
    "    \"\"\"Shannon entropy in bits.\"\"\"\n",
    "    return -sum(p * math.log2(p) for p in probs if p>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c012627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Threshold] Confusing: 75, Non-confusing: 76\n",
      "S-percentiles → min:32.00, 25th:156.00, median:254.00, 75th:380.00, max:825.00\n",
      "H-percentiles → min:1.03, 25th:3.00, median:3.13, 75th:3.20, max:3.32\n",
      "Using S_thresh=254.00 (pct=50), H_thresh=3.13 (pct=50)\n",
      "[Entropy+Sum] Confusing: 344, Non-confusing: 283\n"
     ]
    }
   ],
   "source": [
    "def threshold_classification(questions):\n",
    "    confusing, non_confusing = [], []\n",
    "    for q in questions:\n",
    "        if not is_valid_answer(q['answer']):\n",
    "            continue\n",
    "        for c in q['candidate_answers'].values():\n",
    "            if not is_valid_answer(c):\n",
    "                continue\n",
    "        if q[\"id\"].startswith(\"nq\"):\n",
    "            continue\n",
    "        probs = normalize_scores(q['candidate_answers'])\n",
    "        top_two = sorted(probs, reverse=True)[:2]\n",
    "        if top_two[0] >= 0.5 or sum(top_two) >= 0.5:\n",
    "            confusing.append(q)\n",
    "        elif top_two[0] <= 0.15 or sum(top_two) <= 0.2:\n",
    "            non_confusing.append(q)\n",
    "    return confusing, non_confusing\n",
    "\n",
    "thr_conf, thr_non = threshold_classification(data)\n",
    "print(f\"[Threshold] Confusing: {len(thr_conf)}, Non-confusing: {len(thr_non)}\")\n",
    "\n",
    "def entropy_classification(questions, h_pct=50, s_pct=50, fallback_pct=25):\n",
    "    \"\"\"\n",
    "    Returns two lists: confusing, non_confusing\n",
    "    \n",
    "    confusing     = {q | S >= S_thresh and H >= H_thresh}\n",
    "    non_confusing = {q | S >= S_thresh and H <  H_thresh}\n",
    "    \n",
    "    Where S_thresh = percentile(S_vals, s_pct)\n",
    "          H_thresh = percentile(H_vals, h_pct)\n",
    "          \n",
    "    Prints distribution stats so you can choose sensible cutoffs.\n",
    "    If either pool is empty, retries with fallback_pct.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for q in questions:\n",
    "        if not is_valid_answer(q['answer']): continue\n",
    "        for cand_text in q['candidate_answers'].keys():\n",
    "            if not is_valid_answer(cand_text):\n",
    "                continue   # now this really checks the string \"40\", \"20\", etc.\n",
    "\n",
    "        #if q[\"id\"].startswith(\"nq\"): continue\n",
    "\n",
    "        # Raw scores and sum\n",
    "        scores = [info['listwise'] for info in q['candidate_answers'].values()]\n",
    "        S = sum(scores)\n",
    "        \n",
    "        # Normalize and compute entropy\n",
    "        total = float(S) if S>0 else 1.0\n",
    "        probs = [s / total for s in scores]\n",
    "        H = compute_entropy(probs)\n",
    "\n",
    "        item = q.copy()\n",
    "        item.pop(\"pairwise\", None)\n",
    "        records.append((item, S, H))\n",
    "\n",
    "    if not records:\n",
    "        print(\"No valid records found.\")\n",
    "        return [], []\n",
    "\n",
    "    # Gather S and H arrays\n",
    "    S_vals = np.array([r[1] for r in records])\n",
    "    H_vals = np.array([r[2] for r in records])\n",
    "\n",
    "    # Print distribution summaries\n",
    "    for name, arr in [(\"S\", S_vals), (\"H\", H_vals)]:\n",
    "        p0, p25, p50, p75, p100 = np.percentile(arr, [0,25,50,75,100])\n",
    "        print(f\"{name}-percentiles → min:{p0:.2f}, 25th:{p25:.2f}, median:{p50:.2f}, 75th:{p75:.2f}, max:{p100:.2f}\")\n",
    "\n",
    "    # Compute thresholds\n",
    "    S_thresh = np.percentile(S_vals, s_pct)\n",
    "    H_thresh = np.percentile(H_vals, h_pct)\n",
    "    print(f\"Using S_thresh={S_thresh:.2f} (pct={s_pct}), H_thresh={H_thresh:.2f} (pct={h_pct})\")\n",
    "\n",
    "    # Build strata\n",
    "    confusing = [q for (q,S,H) in records if S >= S_thresh and H >= H_thresh]\n",
    "    non_conf  = [q for (q,S,H) in records if S >= S_thresh and H <  H_thresh]\n",
    "\n",
    "    # If either is empty, retry with fallback_pct\n",
    "    if not confusing or not non_conf:\n",
    "        print(\"Empty stratum detected, retrying thresholds at\", fallback_pct, \"percentile.\")\n",
    "        return entropy_classification(questions, h_pct=fallback_pct, s_pct=fallback_pct, fallback_pct=fallback_pct)\n",
    "\n",
    "    print(f\"[Entropy+Sum] Confusing: {len(confusing)}, Non-confusing: {len(non_conf)}\")\n",
    "    return confusing, non_conf\n",
    "\n",
    "ent_conf, ent_non = entropy_classification(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96617a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Sample for entropy method\\nent_conf_samp = sample_questions(ent_conf, sample_size)\\nent_non_samp  = sample_questions(ent_non, sample_size)\\n# Save to JSON\\nwith open(OUTPUT_DIR + f\\'entropy_{sample_size}_samples.json\\', \\'w\\', encoding=\"utf-8\") as f:\\n    json.dump({\\'confusing\\': ent_conf_samp, \\'non_confusing\\': ent_non_samp}, f, indent=2, ensure_ascii=False)\\nprint(f\"Saved entropy_{sample_size}_samples.json\") '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_questions(q_list, k=5, seed=42):\n",
    "    random.seed(seed)\n",
    "    sample = q_list if len(q_list) < k else random.sample(q_list, k)\n",
    "    if len(q_list) < k:\n",
    "        print(f\"Warning: only {len(q_list)} available; returning all.\")\n",
    "    return sample\n",
    "\n",
    "sample_size = 50\n",
    "\n",
    "entropy_conf_samp = sample_questions(ent_conf, sample_size)\n",
    "entropy_non_samp  = sample_questions(ent_non, sample_size)\n",
    "\n",
    "with open(OUTPUT_DIR + f'entropy_{sample_size}_samples.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump({'confusing': entropy_conf_samp, 'non_confusing': entropy_non_samp}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Save to JSON\n",
    "\"\"\" with open(OUTPUT_DIR + f'threshold_{sample_size}_samples.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump({'confusing': thr_conf_samp, 'non_confusing': thr_non_samp}, f, indent=2, ensure_ascii=True)\n",
    "print(f\"Saved threshold_{sample_size}_samples.json\") \"\"\"\n",
    "\"\"\" \n",
    "# Sample for entropy method\n",
    "ent_conf_samp = sample_questions(ent_conf, sample_size)\n",
    "ent_non_samp  = sample_questions(ent_non, sample_size)\n",
    "# Save to JSON\n",
    "with open(OUTPUT_DIR + f'entropy_{sample_size}_samples.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump({'confusing': ent_conf_samp, 'non_confusing': ent_non_samp}, f, indent=2, ensure_ascii=False)\n",
    "print(f\"Saved entropy_{sample_size}_samples.json\") \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d11df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
