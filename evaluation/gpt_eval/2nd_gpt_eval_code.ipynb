{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ede9651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os, json, random, re\n",
    "import ast\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key\n",
    "OpenAI_Client = openai.OpenAI(\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"cfe-paper\",\n",
    "    },\n",
    "    #base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),   \n",
    ")\n",
    "\n",
    "OpenRouter_Client = openai.OpenAI(\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"cfe-paper\",\n",
    "    },\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),   \n",
    ")\n",
    "EVAL_MODEL = \"openai/gpt-5-2025-08-07\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a108069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_response(system_prompt, user_prompt, model=EVAL_MODEL, reasoning_effort=\"medium\"):\n",
    "    res = OpenRouter_Client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        reasoning_effort=reasoning_effort)\n",
    "    \n",
    "    response_text = res.choices[0].message.content.strip()\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25bd5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/eval_results/gpt/100q_gpt_conf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea3df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we first start with generating the ideal set of candidate answers for each question\n",
    "## we want model to generate incorrect but plausible answers for each question\n",
    "## the number of candidate answers will be up to model, the model will decide how many to generate\n",
    "## we will ask for the ideal number of ideal candidate answers to be generated\n",
    "## also ask the model to explain why each candidate answer is plausible yet incorrect\n",
    "IDEAL_SET_GENERATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert question analyst specializing in educational question answering. You will be given a question along with its correct answer.\n",
    "\n",
    "Your task is to identify the ideal number of plausible but incorrect alternative answers (distractors) for a given factual question. \n",
    "These are the answers that a knowledgeable person might realistically confuse with the correct answer.\n",
    "\n",
    "### Instructions:\n",
    "- List only the plausible but *incorrect* alternatives that could reasonably be mistaken for the correct answer.\n",
    "- Focus on alternatives that can make someone who has some familiarity with the topic hesitate or second-guess themselves.\n",
    "- Do **not** include the correct answer itself or clearly absurd, irrelevant, or far-fetched options.\n",
    "- Add just a one sentence explanation for each alternative, describing why it is plausible yet incorrect.\n",
    "- Do **not** state the number of items explicitly; just list them naturally.\n",
    "- Don't try to minimize or maximize the number of alternatives; just provide the ideal number of alternatives for the given question.\n",
    "- Ensure that your final output is in strict JSON format as specified below.\n",
    "\n",
    "### Output format:\n",
    "{\n",
    "  \"question\": \"<the question here>\",\n",
    "  \"correct_answer\": \"<the correct answer here>\",\n",
    "  \"ideal_candidate_answers\": [\n",
    "    {\n",
    "      \"answer\": \"<plausible but incorrect answer 1>\",\n",
    "      \"explanation\": \"<one sentence explanation for why this answer is plausible yet incorrect>\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"<plausible but incorrect answer 2>\",\n",
    "      \"explanation\": \"<one sentence explanation for why this answer is plausible yet incorrect>\"\n",
    "    } ...\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e023020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ideal_candidate_answers(df, checkpoint_interval=3, out_df=\"../../data/eval_results/gpt/100q_gpt_candidates\"):\n",
    "    filled = 0\n",
    "    questions = df['question'].unique()\n",
    "\n",
    "    for i, question in enumerate(questions, start=1):\n",
    "        rows = df[df['question'] == question]\n",
    "\n",
    "        # 1) skip if non-confusing (use the first row's score for the question)\n",
    "        conf = rows['gpt_conf_score'].iloc[0]\n",
    "        if pd.notnull(conf) and conf <= 50:\n",
    "            print(f\"Low confusion score (<=50), skipping: {question}\")\n",
    "            continue\n",
    "\n",
    "        # 2) skip if already has candidates (for this question)\n",
    "        existing = rows['gpt_cands'].dropna()\n",
    "        if len(existing) > 0:\n",
    "            print(f\"Skipping (already has candidate answers): {question}\")\n",
    "            continue\n",
    "\n",
    "        # 3) prepare prompt\n",
    "        correct_answer = rows['gold_answer'].iloc[0]\n",
    "        user_prompt = f\"Question: {question}\\nCorrect Answer: {correct_answer}\"\n",
    "\n",
    "        # 4) call GPT\n",
    "        try:\n",
    "            response_text = get_api_response(IDEAL_SET_GENERATION_SYSTEM_PROMPT, user_prompt, reasoning_effort=\"medium\")\n",
    "            response_json = json.loads(response_text)\n",
    "            ideal_candidates = response_json.get(\"ideal_candidate_answers\", [])\n",
    "            # optional: sanity check it’s a list of dicts with 'answer'\n",
    "            if not (isinstance(ideal_candidates, list) and all(isinstance(x, dict) and 'answer' in x for x in ideal_candidates)):\n",
    "                raise ValueError(\"ideal_candidate_answers not in expected format.\")\n",
    "\n",
    "            print(f\"{user_prompt}\\nGenerated Ideal Candidates:\")\n",
    "            for i_cand in ideal_candidates:\n",
    "                print(f\"- Answer: {i_cand['answer']} | Explanation: {i_cand['explanation']}\")\n",
    "            print(\"****************************\")\n",
    "\n",
    "            # 5) write to ALL rows of this question (consistent)\n",
    "            df.loc[df['question'] == question, 'gpt_cands'] = json.dumps(ideal_candidates)\n",
    "            filled += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{question}': {e}\")\n",
    "            # leave as NaN; we can retry later\n",
    "\n",
    "        # 6) checkpoint every N successful fills\n",
    "        if filled > 0 and filled % checkpoint_interval == 0:\n",
    "            out_df_path = f\"{out_df}_ckpt_{filled}.csv\"\n",
    "            df.to_csv(out_df_path, index=False)\n",
    "            print(f\"Checkpoint saved ({filled} filled): {out_df_path}\")\n",
    "\n",
    "    # FINAL SAVE (no column overwrite!)\n",
    "    out_df_path = f\"{out_df}_final.csv\"\n",
    "    df.to_csv(out_df_path, index=False)\n",
    "    print(f\"Final saved: {out_df_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc8c4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_df = pd.read_csv(\"../../data/eval_results/gpt/100q_gpt_candidates86.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6be55609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low confusion score (<=50), skipping: \"Feel Like Making Love\" and \"The First Time Ever I Saw Your Face\" were hit singles for which female artist?\n",
      "Low confusion score (<=50), skipping: Anellini pasta is what type of shape?\n",
      "Skipping (already has candidate answers): Art Garfunkel trained for which profession although he didn't qualify?\n",
      "Question: At 7am on Saturday 19 May 2012 which gold medalist started the torch delay in Lands End?\n",
      "Correct Answer: Ben Ainslie\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Sir Steve Redgrave | Explanation: As a five-time Olympic rowing champion who carried the torch into the Olympic Stadium and was central to the cauldron handover, many assume he also started the relay.\n",
      "- Answer: Sir Chris Hoy | Explanation: The multiple Olympic cycling champion was a prominent figure of London 2012 and a torchbearer, making him an easy but incorrect guess for the relay’s start.\n",
      "- Answer: Sir Bradley Wiggins | Explanation: Already an Olympic gold medalist and a high-profile figure who rang the bell at the opening ceremony, he is often associated with key London 2012 moments.\n",
      "- Answer: Sebastian Coe | Explanation: The double Olympic champion and chair of the London 2012 organizing committee was present at the Land’s End kickoff, which leads some to wrongly think he began the relay.\n",
      "- Answer: Dame Kelly Holmes | Explanation: The double Olympic champion carried the torch during the relay and lit celebration cauldrons, which can be confused with starting the relay.\n",
      "- Answer: Sir Matthew Pinsent | Explanation: The four-time Olympic rowing champion had high-profile torchbearing duties near the Games, prompting confusion about him starting the relay at Land’s End.\n",
      "****************************\n",
      "Skipping (already has candidate answers): At which English racecourse would you see the 'Hennessy Gold Cup'?\n",
      "Low confusion score (<=50), skipping: Brazilian football legend Pele wore which number on his shirt?\n",
      "Skipping (already has candidate answers): British MP, Diane Abbott, learned to play which musical instrument in the tv series ‘Play It Again’?\n",
      "Low confusion score (<=50), skipping: Complete the title of this 1970's group 'Sutherland Brothers and ….'?\n",
      "Low confusion score (<=50), skipping: Elvis Presley’s manager, Andreas Cornelis van Kujik, was better known by what name?\n",
      "Question: Eunice was the mother of which New Testament figure, the recipient of two epistles from Saint Paul?\n",
      "Correct Answer: Timothy\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Titus | Explanation: He was a close associate of Paul and the addressee of one pastoral epistle, which can be confused with Timothy’s two letters, but he was not Eunice’s son.\n",
      "- Answer: Philemon | Explanation: He received a personal letter from Paul, making him a tempting choice, yet he has no familial connection to Eunice and did not receive two epistles.\n",
      "- Answer: Onesimus | Explanation: As the central figure in Paul’s letter to Philemon and called Paul’s ‘child,’ he might be confused with a mentee like Timothy, but he was not Eunice’s son nor the recipient of two letters.\n",
      "- Answer: Silas | Explanation: Often mentioned alongside Paul and Timothy in Acts, he could be mixed up by association, but there is no epistle addressed to him and no link to Eunice.\n",
      "- Answer: John Mark | Explanation: A companion of Paul and Barnabas and mentioned in 2 Timothy, he might be conflated with Timothy’s circle, but he was not Eunice’s son and did not receive Pauline epistles.\n",
      "****************************\n",
      "Checkpoint saved (2 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_2.csv\n",
      "Low confusion score (<=50), skipping: Fidel Castro, former President of Cuba, ordered which board game to be destroyed when he took power?\n",
      "Low confusion score (<=50), skipping: Flemish is almost identical in form to which other language ?\n",
      "Low confusion score (<=50), skipping: From which 1960s sci-fi movie did 1980s pop sensation Duran Duran take their name from a character from the movie?\n",
      "Low confusion score (<=50), skipping: Harvey Littleton, Dominick Labino, Dale Chihuly, Dante Marioni, Fritz Driesbach and Marvin Lipofsky are associated with producing art from what material?\n",
      "Skipping (already has candidate answers): How many films were made by director Sir Peter Jackson from Tolkien's short book, \"The Hobbit\"?\"\n",
      "Low confusion score (<=50), skipping: If a square sheet of paper is folded diagonally in half, the resulting two sharp corners are each how many degrees?\n",
      "Question: In the 1965 film ‘Those Magnificent Men in Their Flying Machines’, how much is the prize money, in pounds sterling, for the fastest flight from London to Paris?\n",
      "Correct Answer: 10000\n",
      "Generated Ideal Candidates:\n",
      "- Answer: 5000 | Explanation: A lower, more modest figure fits period aviation prizes and is easy to misremember as the amount offered in the film.\n",
      "- Answer: 20000 | Explanation: People sometimes recall a rounded higher sum or conflate it with other publicity or prize amounts from the era.\n",
      "- Answer: 15000 | Explanation: This sounds like a plausible midpoint often used in promotions or contests and could be mistakenly remembered as the film’s prize.\n",
      "- Answer: 25000 | Explanation: This can be confused with famous aviation prizes like the Orteig Prize (though in dollars), leading to an inflated memory of the film’s amount.\n",
      "- Answer: 10500 | Explanation: Someone recalling '10,000 guineas' instead of pounds would convert to £10,500, a plausible but incorrect figure.\n",
      "****************************\n",
      "Low confusion score (<=50), skipping: In the King James Version, which eponymous book of the Old Testament follows 'Esther' and precedes 'Psalms'?\n",
      "Skipping (already has candidate answers): In the Sherlock Holmes stories who was Moriarty’s second in command?\n",
      "Low confusion score (<=50), skipping: In the acronym REM, which describes stage of sleep during which dreams occur, for what does the R stand ?\n",
      "Skipping (already has candidate answers): In which country was the inventor of the machine gun Hiram Maxim born?\n",
      "Question: In which year was the 'Boxing Day Tsunami' in the Indian Ocean?\n",
      "Correct Answer: 2004\n",
      "Generated Ideal Candidates:\n",
      "- Answer: 2005 | Explanation: The aftermath and major aftershocks in the region, including the deadly Nias earthquake in March 2005, can lead people to associate the disaster with the following year.\n",
      "- Answer: 2003 | Explanation: The devastating Bam earthquake in Iran occurred on December 26, 2003 (Boxing Day), which can make the date feel familiar even though it was not a tsunami.\n",
      "- Answer: 2006 | Explanation: A significant tsunami hit the south coast of Java in July 2006, causing many deaths in the Indian Ocean region and potentially causing confusion with the Boxing Day event.\n",
      "- Answer: 2010 | Explanation: The Mentawai Islands earthquake and tsunami off Sumatra in October 2010 were in the Indian Ocean and may be conflated with the 2004 disaster.\n",
      "- Answer: 2011 | Explanation: The catastrophic Tohoku earthquake and tsunami in Japan in 2011 is one of the most famous tsunamis and can be mistakenly recalled as the Indian Ocean event.\n",
      "****************************\n",
      "Checkpoint saved (4 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_4.csv\n",
      "Skipping (already has candidate answers): In ‘Follow That Camel’, the fourteenth Carry On film, Sid James was replaced by which US actor?\n",
      "Low confusion score (<=50), skipping: Italy is divided into how many regions?\n",
      "Low confusion score (<=50), skipping: Legend has it in Britain that which bird never uses its voice until it is dying?\n",
      "Question: Michael Morpurgo, author of the children's book War Horse, on which the 2012 Spielberg film (of the same name) is based, held what UK position from 2003-5?\n",
      "Correct Answer: Children's Laureate\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Poet Laureate | Explanation: This is the high-profile national laureateship many think of first, and its title sounds similar, but it pertains to poetry for all ages, not specifically children's literature.\n",
      "- Answer: Children's Commissioner for England | Explanation: This is a national child-focused role created around the same time, but it's a policy and advocacy post rather than a literary laureateship.\n",
      "- Answer: Children's Poet Laureate | Explanation: The title exists (notably in the U.S.) and sounds very close, but it is a different role and not the UK-wide children's literature laureateship Morpurgo held.\n",
      "- Answer: Laureate na nÓg (Ireland's Children's Laureate) | Explanation: This is a children's literature laureateship like the UK's, which could cause confusion, but it is the Irish post, not the UK one.\n",
      "- Answer: UK Storytelling Laureate | Explanation: This is a real UK laureateship with a similar-sounding title, but it focuses on oral storytelling and is distinct from the children's literature laureateship.\n",
      "****************************\n",
      "Low confusion score (<=50), skipping: Name the French artist (1839-1906) whose painting 'The Card Players' is one of the most expensive ever sold?\n",
      "Skipping (already has candidate answers): Name the head of the 'whistleblowing' website Wikileaks, in the news during 2010 after publishing thousands of sensitive government and military documents?\n",
      "Question: Name the manufacturer of the British World War II bomber the Lancaster?\n",
      "Correct Answer: AVRO\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Handley Page | Explanation: Handley Page built the Halifax, another major RAF heavy bomber often mentioned alongside the Lancaster, making it an easy mix-up.\n",
      "- Answer: Short Brothers | Explanation: Short Brothers produced the Stirling, the RAF’s first four-engined heavy bomber of the war, which can be confused with the Lancaster.\n",
      "- Answer: Vickers-Armstrongs | Explanation: Vickers-Armstrongs made the well-known Wellington bomber, leading some to assume they also built the Lancaster.\n",
      "- Answer: Armstrong Whitworth | Explanation: Armstrong Whitworth manufactured the Whitley bomber, another RAF type from the same era that can cause confusion over manufacturers.\n",
      "- Answer: de Havilland | Explanation: De Havilland produced the famous Mosquito fast bomber, a high-profile WWII aircraft that some might mistakenly associate with the Lancaster.\n",
      "****************************\n",
      "Checkpoint saved (6 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_6.csv\n",
      "Low confusion score (<=50), skipping: On which part of the body would a Japanese person wear a geta?\n",
      "Low confusion score (<=50), skipping: The Mekong River rises in the Tibetan plateau and runs through or between six countries - China, Burma, Thailand, Cambodia, Vietnam and which other?\n",
      "Skipping (already has candidate answers): The collective noun for which British mammal is a 'cete'? [say “Seat”]?\n",
      "Low confusion score (<=50), skipping: What is the distinctive colour of the soles of shoes designed by Christian Louboutin?\n",
      "Low confusion score (<=50), skipping: What is the first name of \"Seinfeld\"?\"\n",
      "Question: What is the name for a rotating rod with oblong lobes sticking out of it, that is fitted in a car's engine block?\n",
      "Correct Answer: Camshaft\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Crankshaft | Explanation: It’s a major rotating shaft in the engine block and is often confused with the camshaft, but it has offset journals for pistons rather than oblong lobes for valve actuation.\n",
      "- Answer: Balance shaft | Explanation: This shaft also rotates in the engine block and has offset counterweights that can look like lobes, but its purpose is to cancel vibrations, not operate valves.\n",
      "- Answer: Pushrod | Explanation: Pushrods are part of the valvetrain and are driven by the camshaft, but they are slender rods without lobes and do not directly control valve timing.\n",
      "- Answer: Rocker arm | Explanation: Rocker arms pivot to open and close valves and are part of the valvetrain, but they are not a rotating rod with lobes.\n",
      "- Answer: Tappet (lifter) | Explanation: A tappet or lifter rides on the cam lobes and transfers motion, which can cause confusion, but it is a small follower component rather than the lobed shaft itself.\n",
      "- Answer: Eccentric shaft | Explanation: Some engines use an eccentric shaft with off-center lobes (e.g., for variable valve lift), which resembles a camshaft, but it is a different component with a different function.\n",
      "****************************\n",
      "Low confusion score (<=50), skipping: What is the smallest Canadian province?\n",
      "Skipping (already has candidate answers): What is the surname of Django in the 2012 film ‘Django Unchained’?\n",
      "Question: What number is Hurricane on the Beaufort Scale?\n",
      "Correct Answer: 12\n",
      "Generated Ideal Candidates:\n",
      "- Answer: 11 | Explanation: Force 11 is a violent storm just below hurricane strength, so people often misremember it as the hurricane level.\n",
      "- Answer: 10 | Explanation: Force 10 is labeled a storm, which some may mistakenly equate with hurricane conditions.\n",
      "- Answer: 13 | Explanation: Some extended versions of the Beaufort scale continue beyond 12, leading people to think hurricane might start at 13.\n",
      "- Answer: 17 | Explanation: In certain regional extensions the scale goes up to 17, so someone might assume the highest number corresponds to hurricane force.\n",
      "- Answer: 5 | Explanation: This confuses the Beaufort scale with the Saffir–Simpson hurricane categories, where Category 5 is the strongest hurricane.\n",
      "- Answer: 9 | Explanation: Force 9 is a severe gale and can be mistakenly equated with hurricane conditions by those conflating gale and hurricane terminology.\n",
      "****************************\n",
      "Checkpoint saved (8 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_8.csv\n",
      "Low confusion score (<=50), skipping: What traditional dark ale is said to derive from its consumption by early 1700s doormen and bag-carrying street workers?\n",
      "Low confusion score (<=50), skipping: What type of exhibit can be seen in the military museum at Bovington in Dorset?\n",
      "Question: What was the name of George Stephenson's first railway locomotive, built in 1814?\n",
      "Correct Answer: Blucher\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Rocket | Explanation: Built by George and Robert Stephenson in 1829 for the Rainhill Trials, Rocket is famous but was not his first locomotive nor from 1814.\n",
      "- Answer: Locomotion No. 1 | Explanation: Stephenson built Locomotion No. 1 in 1825 for the Stockton and Darlington Railway, making it earlier than Rocket but not his first locomotive.\n",
      "- Answer: Puffing Billy | Explanation: An 1813 locomotive often cited among the earliest, Puffing Billy was built by Hedley and partners at Wylam, not by Stephenson.\n",
      "- Answer: Wylam Dilly | Explanation: This early locomotive from 1815 is closely associated with the same region and era but was built by Hedley’s team, not Stephenson.\n",
      "- Answer: Sans Pareil | Explanation: A competitor at the 1829 Rainhill Trials, Sans Pareil was built by Timothy Hackworth rather than Stephenson.\n",
      "- Answer: Northumbrian | Explanation: A notable Stephenson engine from 1830 on the Liverpool and Manchester Railway, Northumbrian came much later than his first 1814 locomotive.\n",
      "****************************\n",
      "Low confusion score (<=50), skipping: What was the name of the short-lived republic that existed in south-eastern Nigeria between 1967 and 1970?\n",
      "Low confusion score (<=50), skipping: What whole two-digit number is the square root of 9801?\n",
      "Skipping (already has candidate answers): What year did the Channel Tunnel between Britain and France open?\n",
      "Question: Which English town/city did the Romans call Dubris?\n",
      "Correct Answer: Dover\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Canterbury | Explanation: Its Roman name Durovernum Cantiacorum shares the 'Du-' prefix and it is also in Kent, making it easy to confuse with Dubris.\n",
      "- Answer: Rochester | Explanation: Known to the Romans as Durobrivae/Durobrivis, it has a very similar 'Duro-' beginning and is another Kent location.\n",
      "- Answer: Dorchester | Explanation: Its Roman name Durnovaria starts with 'Dur-', which can be mixed up with 'Dub-' by those recalling Latin place-name roots.\n",
      "- Answer: Richborough (Sandwich) | Explanation: As the Roman port of Rutupiae in Kent, it was another key Channel site that can be mistaken for Dover’s Roman port.\n",
      "- Answer: Lympne | Explanation: Home to the Saxon Shore fort Portus Lemanis, it guarded the same coastline as Dover and is sometimes conflated with it.\n",
      "****************************\n",
      "Checkpoint saved (10 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_10.csv\n",
      "Skipping (already has candidate answers): Which German mathematician, physicist and astonomer (1777 - 1855) was involved in the first worldwide survey of the Earth's magnetic field and gives his name to a unit of magnetic induction ?\n",
      "Low confusion score (<=50), skipping: Which car manufacturer has its headquarters at Martorell near Barcelona?\n",
      "Question: Which city was the subject of the 1949 song 'Dirty Old Town' by Ewan McColl?\n",
      "Correct Answer: Salford\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Manchester | Explanation: Salford borders Manchester and is often conflated with it, leading many to assume the song refers to the larger neighboring city.\n",
      "- Answer: Dublin | Explanation: The song was popularized by Irish folk groups like The Dubliners, causing some to think it was written about Dublin.\n",
      "- Answer: Glasgow | Explanation: Its heavy industrial past and similar gritty urban imagery make Glasgow a plausible but incorrect guess.\n",
      "- Answer: Belfast | Explanation: The city's shipyards and industrial character match the song’s atmosphere, and Irish folk renditions can mislead listeners.\n",
      "- Answer: Liverpool | Explanation: As another North West industrial port city near Salford, Liverpool fits the song’s mood and is easily mistaken as the subject.\n",
      "****************************\n",
      "Low confusion score (<=50), skipping: Which element has the chemical symbol Cs?\n",
      "Low confusion score (<=50), skipping: Which four letter word beginning with T is a small mountain lake?\n",
      "Skipping (already has candidate answers): Which group of large insects includes hawkers and darters, named for their flying styles?\n",
      "Question: Which journalist first told the world about the My Lai massacre?\n",
      "Correct Answer: Sy Hersh\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Ron Ridenhour | Explanation: His letters to officials sparked the investigations into My Lai, leading some to credit him with the exposure even though he was not the journalist who first reported it publicly.\n",
      "- Answer: Ronald L. Haeberle | Explanation: The Army photographer’s shocking images later published in newspapers and magazines made My Lai widely known, causing some to mistake him for the original reporter.\n",
      "- Answer: Mike Wallace | Explanation: The 60 Minutes journalist conducted prominent televised interviews with participants after the story emerged, which can lead to confusion about who first broke it.\n",
      "- Answer: Morley Safer | Explanation: His famous Vietnam reporting on the Cam Ne village burning is sometimes conflated with My Lai due to its similar theme of wartime atrocities.\n",
      "- Answer: Neil Sheehan | Explanation: Known for breaking the Pentagon Papers and early Vietnam reporting, he is often associated with major Vietnam exposés but did not first report My Lai.\n",
      "- Answer: Peter Arnett | Explanation: An AP correspondent renowned for Vietnam coverage, he is a plausible but incorrect choice because he did not break the My Lai story.\n",
      "- Answer: David Halberstam | Explanation: A Pulitzer-winning Vietnam reporter whose critical coverage of the war can be misremembered as including the first revelation of My Lai.\n",
      "****************************\n",
      "Checkpoint saved (12 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_12.csv\n",
      "Skipping (already has candidate answers): Which nineteenth century artist had the Christian names John Everett?\n",
      "Question: Which river runs through York?\n",
      "Correct Answer: OUSE\n",
      "Generated Ideal Candidates:\n",
      "- Answer: River Derwent | Explanation: The Derwent flows close to York and joins the Ouse downstream at Barmby on the Marsh, so it’s easy to confuse it with the river in the city.\n",
      "- Answer: River Wharfe | Explanation: The Wharfe passes through Tadcaster near York and meets the Ouse at Cawood south of the city, which can mislead those familiar with the area.\n",
      "- Answer: River Nidd | Explanation: The Nidd joins the Ouse at Nun Monkton northwest of York, making it part of the same system but not the river through the city.\n",
      "- Answer: River Ure | Explanation: The Ure is effectively the upper course that becomes the Ouse, and some sources conflate the names, causing confusion about which passes through York.\n",
      "- Answer: River Aire | Explanation: The Aire is a major Yorkshire river that meets the Ouse at Airmyn near Goole downstream of York, which can lead to a mistaken association with the city.\n",
      "****************************\n",
      "Low confusion score (<=50), skipping: Which society was founded in 1946 by barrister Roland Berrill & scientist Dr Lance Ware?\n",
      "Low confusion score (<=50), skipping: Which tennis player was known as the Rockhampton Rocket?\n",
      "Low confusion score (<=50), skipping: Who had a No 1 in the 80's with Karma Chameleon?\n",
      "Skipping (already has candidate answers): Who is the composer of \"The L'Arlesienne Suite\"?\"\n",
      "Question: Who painted The Luncheon of the Boating Party in 1881?\n",
      "Correct Answer: Renoir\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Édouard Manet | Explanation: Manet is often confused with Renoir and painted the similarly titled Déjeuner sur l'herbe, which can mislead those recalling a 'luncheon' painting.\n",
      "- Answer: Claude Monet | Explanation: Monet frequently depicted leisure and boating scenes and collaborated with Renoir, making authorship easy to confuse.\n",
      "- Answer: Gustave Caillebotte | Explanation: Caillebotte is known for rowing and boating subjects and even appears in the painting, which can prompt misattribution.\n",
      "- Answer: Georges Seurat | Explanation: Seurat's A Sunday Afternoon on the Island of La Grande Jatte is another iconic riverside leisure scene that some might mix up with Renoir's work.\n",
      "- Answer: Mary Cassatt | Explanation: Cassatt painted The Boating Party, and the similar title can cause confusion despite being a different artist and later date.\n",
      "****************************\n",
      "Checkpoint saved (14 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_14.csv\n",
      "Low confusion score (<=50), skipping: Who plays the role of Bubble in Absolutely Fabulous?\n",
      "Low confusion score (<=50), skipping: Who wrote the novels About A Boy, How To Be Good and High Fidelity?\n",
      "Skipping (already has candidate answers): Whom did Malcolm III kill in battle in 1057 to become King of Scotland?\n",
      "Low confusion score (<=50), skipping: Whose summer residence is at Lake Gandalfo, a small town south-east of Rome?\n",
      "Low confusion score (<=50), skipping: how many episodes is ash vs evil dead season 3?\n",
      "Question: how many episodes of sabrina the teenage witch are there?\n",
      "Correct Answer: 163\n",
      "Generated Ideal Candidates:\n",
      "- Answer: 162 | Explanation: Some sources merge a two-part episode (such as the finale) into a single entry, reducing the count by one.\n",
      "- Answer: 164 | Explanation: This total results from counting the 1996 TV movie pilot as part of the episode tally.\n",
      "- Answer: 165 | Explanation: Including the two Melissa Joan Hart TV movies (Sabrina Goes to Rome and Sabrina Down Under) along with the series episodes yields this number.\n",
      "- Answer: 166 | Explanation: Counting the 1996 TV movie pilot plus the two later TV movies in addition to the series episodes gives this higher total.\n",
      "****************************\n",
      "Skipping (already has candidate answers): in which US State is the Chambers Bay Course, the venue for the 2015 US Open Golf Championship?\n",
      "Question: the general term for software that is designed to damage disable or steal data is?\n",
      "Correct Answer: Malware\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Computer virus | Explanation: A virus is a specific type of malicious software, not the umbrella term for all harmful software.\n",
      "- Answer: Trojan horse | Explanation: A Trojan is one category of malicious software that disguises itself as legitimate, but it is not the general term.\n",
      "- Answer: Spyware | Explanation: Spyware is a subtype focused on secretly gathering information, not the overarching category.\n",
      "- Answer: Ransomware | Explanation: Ransomware is a particular kind of malicious software that encrypts data for ransom, not the general label.\n",
      "- Answer: Worm | Explanation: A worm is a self-replicating type of malicious software, not the broad term for all such software.\n",
      "****************************\n",
      "Checkpoint saved (16 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_16.csv\n",
      "Skipping (already has candidate answers): what class of ship is the carnival glory?\n",
      "Question: what county is texarkana arkansas in?\n",
      "Correct Answer: Miller County\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Bowie County | Explanation: The Texas side of Texarkana is in Bowie County, which often leads people to confuse it with the Arkansas side.\n",
      "- Answer: Hempstead County | Explanation: It lies just north of Miller County along I-30 and includes nearby towns like Hope, making county boundaries easy to mix up.\n",
      "- Answer: Lafayette County | Explanation: This county borders Miller County to the east, so some assume Texarkana extends into it.\n",
      "- Answer: Little River County | Explanation: It neighbors Miller County to the northwest, and proximity can cause confusion about Texarkana’s county.\n",
      "****************************\n",
      "Skipping (already has candidate answers): what is don quixote 's horse 's name?\n",
      "Low confusion score (<=50), skipping: what is the third season of total drama?\n",
      "Low confusion score (<=50), skipping: what timezone is utah in?\n",
      "Low confusion score (<=50), skipping: when did the ship hector arrived in pictou?\n",
      "Question: when does season 6 of the next step start?\n",
      "Correct Answer: 2018\n",
      "Generated Ideal Candidates:\n",
      "- Answer: 2019 | Explanation: Many international broadcasts (such as CBBC in the UK) and the season’s run extended into 2019, leading some viewers to associate the start with that year.\n",
      "- Answer: 2017 | Explanation: Season 5 began in 2017, so timelines can blur and make it seem like Season 6 kicked off that same year.\n",
      "- Answer: 2020 | Explanation: Season 7 launched in 2020 and some regions or streaming platforms updated Season 6 around then, causing confusion about the start year.\n",
      "****************************\n",
      "Checkpoint saved (18 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_18.csv\n",
      "Skipping (already has candidate answers): when does the miz and maryse show start?\n",
      "Question: when was harry potter and the philosopher 's stone made?\n",
      "Correct Answer: 1997\n",
      "Generated Ideal Candidates:\n",
      "- Answer: 2001 | Explanation: The film adaptation Harry Potter and the Philosopher's Stone was released in cinemas in 2001, which many might interpret as when it was made.\n",
      "- Answer: 1998 | Explanation: The book was published in the United States (retitled as Sorcerer's Stone) in 1998, which can be confused with its original publication date.\n",
      "- Answer: 1996 | Explanation: Bloomsbury accepted Rowling's manuscript in 1996, a key milestone sometimes mistaken for the book's release year.\n",
      "- Answer: 1995 | Explanation: Rowling completed the manuscript in 1995, which could be taken as when it was made in the sense of being written.\n",
      "- Answer: 2000 | Explanation: Principal photography for the film began in 2000, so those thinking about the movie's production might choose this date.\n",
      "****************************\n",
      "Skipping (already has candidate answers): when was penicillin first introduced to the public?\n",
      "Question: where did the indian myna bird come from?\n",
      "Correct Answer: Asia\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Australia | Explanation: It is a notorious invasive pest across eastern Australia, leading many to assume it is native there.\n",
      "- Answer: South Africa | Explanation: Established populations exist in South Africa, which can mislead people into thinking it originated on the African continent.\n",
      "- Answer: New Zealand | Explanation: The species was introduced to New Zealand and became familiar locally, creating confusion about its origin.\n",
      "- Answer: Hawaii | Explanation: It was introduced to Hawaii in the 19th century and is now widespread, making some believe it is native there.\n",
      "- Answer: Fiji | Explanation: It is common in Fiji after introduction, so its prevalence can be mistaken for native origin.\n",
      "****************************\n",
      "Checkpoint saved (20 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_20.csv\n",
      "Skipping (already has candidate answers): where is electrolux based?\n",
      "Question: who built the first temple for god in jerusalem?\n",
      "Correct Answer: Solomon\n",
      "Generated Ideal Candidates:\n",
      "- Answer: David | Explanation: David planned the temple and gathered materials, but was told by God that his son would build it.\n",
      "- Answer: Zerubbabel | Explanation: Zerubbabel led the rebuilding of the temple after the Babylonian exile, which was the Second Temple, not the first.\n",
      "- Answer: Herod the Great | Explanation: Herod massively renovated and expanded the Second Temple, but he did not build the original temple.\n",
      "- Answer: Hiram of Tyre | Explanation: Hiram supplied cedar, craftsmen, and support for the project, but he was not the one who built the temple.\n",
      "- Answer: Cyrus the Great | Explanation: Cyrus authorized and financed the rebuilding of the temple after the exile, but this was centuries after the first temple.\n",
      "****************************\n",
      "Skipping (already has candidate answers): who formed and first came to the colony of maryland?\n",
      "Question: who has made the most premier league appearances?\n",
      "Correct Answer: Gareth Barry\n",
      "Generated Ideal Candidates:\n",
      "- Answer: James Milner | Explanation: He ranks second on the all-time Premier League appearances list and some may think his longevity recently carried him past Barry.\n",
      "- Answer: Ryan Giggs | Explanation: He previously held the record for most Premier League appearances before Gareth Barry surpassed him.\n",
      "- Answer: Frank Lampard | Explanation: He is among the top appearance-makers and a hugely prominent Premier League figure, which can make him seem like the record-holder.\n",
      "- Answer: David James | Explanation: He has the most Premier League appearances by a goalkeeper and sits high on the overall list, making him an easy guess.\n",
      "- Answer: Gary Speed | Explanation: A stalwart across many Premier League seasons and long cited among the leaders in appearances, though not the overall record-holder.\n",
      "****************************\n",
      "Checkpoint saved (22 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_22.csv\n",
      "Skipping (already has candidate answers): who has the most big ten championships in football?\n",
      "Question: who is the voice of the other mother in coraline?\n",
      "Correct Answer: Teri Hatcher\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Dakota Fanning | Explanation: She voices Coraline Jones, the protagonist, which can lead people to mistakenly assume she also voiced the Other Mother.\n",
      "- Answer: Helena Bonham Carter | Explanation: She is closely associated with Tim Burton–style stop-motion like Corpse Bride, causing confusion with Coraline’s similar aesthetic, but she is not in Coraline.\n",
      "- Answer: Catherine O'Hara | Explanation: Known for voicing iconic Burton stop-motion roles such as Sally in The Nightmare Before Christmas, she is often misattributed to Coraline’s villain.\n",
      "- Answer: Jennifer Saunders | Explanation: She appears in Coraline but voices Miss Spink, not the Other Mother.\n",
      "- Answer: Dawn French | Explanation: She is in the Coraline cast as Miss Forcible, which some may confuse with the Other Mother role.\n",
      "****************************\n",
      "Skipping (already has candidate answers): who played chaka on land of the lost tv show?\n",
      "Question: who plays the scary nun in the conjuring 2?\n",
      "Correct Answer: Bonnie Aarons\n",
      "Generated Ideal Candidates:\n",
      "- Answer: Taissa Farmiga | Explanation: She stars as Sister Irene in The Nun spin-offs, leading some to conflate her with the demon nun from The Conjuring 2.\n",
      "- Answer: Vera Farmiga | Explanation: She plays Lorraine Warren in The Conjuring films and shares many scenes with the nun, which can cause mix-ups.\n",
      "- Answer: Javier Botet | Explanation: He portrayed the Crooked Man in The Conjuring 2, and his reputation for creature roles makes it easy to assume he also played the nun.\n",
      "- Answer: Joseph Bishara | Explanation: As the franchise’s composer who has also physically portrayed demons in these films, he’s often mistakenly credited with playing Valak.\n",
      "- Answer: Doug Jones | Explanation: A famous creature performer frequently assumed to be behind many horror characters in heavy makeup, leading to misattribution here.\n",
      "****************************\n",
      "Checkpoint saved (24 filled): ../../data/eval_results/gpt/100q_gpt_candidates_ckpt_24.csv\n",
      "Skipping (already has candidate answers): who sings the rap in baby by justin bieber?\n",
      "Low confusion score (<=50), skipping: who turns into a bear in the hobbit?\n",
      "Final saved: ../../data/eval_results/gpt/100q_gpt_candidates_final.csv\n"
     ]
    }
   ],
   "source": [
    "generate_ideal_candidate_answers(checkpoint_df, checkpoint_interval=2, out_df=\"../../data/eval_results/gpt/100q_gpt_candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65888a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the intersection of mentioned_cands and gpt_candidate_answers \n",
    "# by based on the phrasing of the options of gpt_candidate_answers\n",
    "INTERSECTION_SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert semantic evaluator.\n",
    "Your task is to find the semantic intersection between two lists of entity names. \n",
    "You will be provided with List A and List B.\n",
    "### Instructions:\n",
    "- Identify entities that are semantically equivalent between the two lists.\n",
    "- We consider entities to be semantically equivalent if they are the abbreviated, synonymous, or slight variations of each other that represent the same thing.\n",
    "- Return a JSON array containing the names of the entities that are present in both lists based on semantic similarity.\n",
    "- Ensure that the output is a valid JSON array.\n",
    "### Output format:\n",
    "[\n",
    "  \"<entity name 1>\",\n",
    "  \"<entity name 2>\",\n",
    "  ...\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa71764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intersections(df, checkpoint_interval = 2, out_df_path=\"../../data/results/100q_with_gpt_intersections.csv\"):\n",
    "    all_intersections = []\n",
    "    grouped = df.groupby(\"question\")\n",
    "    for idx, group in enumerate(grouped):\n",
    "        question, rows = group\n",
    "        mentioned_cands = rows['mentioned_cands'].iloc[0]\n",
    "        gpt_cands = rows['gpt_cands'].iloc[0]\n",
    "        if pd.isnull(mentioned_cands) or pd.isnull(gpt_cands):\n",
    "            all_intersections.append([])\n",
    "            print(f\"Skipping question '{question}', missing data.\")\n",
    "            continue\n",
    "        try:\n",
    "            mentioned_cands_list = ast.literal_eval(mentioned_cands)\n",
    "            gpt_cands_list = [item['answer'] for item in ast.literal_eval(gpt_cands)]\n",
    "            user_prompt = f\"List A: {mentioned_cands_list}\\nList B: {gpt_cands_list}\"\n",
    "            response_text = get_api_response(INTERSECTION_SYSTEM_PROMPT, user_prompt, reasoning_effort=\"low\")\n",
    "            response_json = json.loads(response_text)\n",
    "            print(f\"{user_prompt}\\nIntersection: {response_json}\\n\")\n",
    "            print(\"****************************\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question '{question}': {e}\")\n",
    "            response_json = []\n",
    "        all_intersections.append(response_json)\n",
    "        if (idx + 1) % checkpoint_interval == 0:\n",
    "            df.loc[df['question'] == question, 'gpt_cands_intersection'] = json.dumps(all_intersections[-1])\n",
    "            df.to_csv(out_df_path, index=False)\n",
    "            print(f\"Checkpoint saved at question {idx + 1}\")\n",
    "    # Final save\n",
    "    df['gpt_cands_intersection'] = pd.Series(all_intersections)\n",
    "    df.to_csv(out_df_path, index=False)\n",
    "    print(\"Final checkpoint saved after all questions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06c1e9c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_intersections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_df_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/results/100q_with_gpt_candidates.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 8\u001b[0m, in \u001b[0;36mget_intersections\u001b[1;34m(df, checkpoint_interval, out_df_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m mentioned_cands \u001b[38;5;241m=\u001b[39m rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmentioned_cands\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m gpt_candidate_answers \u001b[38;5;241m=\u001b[39m rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_candidate_answers\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(mentioned_cands) \u001b[38;5;129;01mor\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(gpt_candidate_answers):\n\u001b[0;32m      9\u001b[0m     all_intersections\u001b[38;5;241m.\u001b[39mappend([])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping question \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, missing data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "get_intersections(df, checkpoint_interval = 2, out_df_path=\"../../data/results/100q_with_gpt_candidates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, out_df_path=\"../../data/results/100q_gpt_candidates.csv\"):\n",
    "    precisions, recalls, f1_scores = [], [], []\n",
    "    for idx, row in df.iterrows():\n",
    "        mentioned_cands = row['mentioned_cands']\n",
    "        gpt_cands = row['gpt_cands']\n",
    "        intersection = row['gpt_cands_intersection']\n",
    "\n",
    "        if pd.isnull(mentioned_cands) or pd.isnull(gpt_cands) or pd.isnull(intersection):\n",
    "            precisions.append(np.nan)\n",
    "            recalls.append(np.nan)\n",
    "            f1_scores.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            mentioned_cands_list = ast.literal_eval(mentioned_cands)\n",
    "            gpt_cands_list = [item['answer'] for item in ast.literal_eval(gpt_cands)]\n",
    "            intersection_list = ast.literal_eval(intersection)\n",
    "\n",
    "            tp = len(intersection_list)\n",
    "            fp = len(mentioned_cands_list) - tp     # mentioned but not in ideal\n",
    "            fn = len(gpt_cands_list) - tp  # ideal but not mentioned\n",
    "\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1_score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating metrics for row {idx}: {e}\")\n",
    "            precisions.append(np.nan)\n",
    "            recalls.append(np.nan)\n",
    "            f1_scores.append(np.nan)\n",
    "\n",
    "    df['gpt_precision'] = precisions\n",
    "    df['gpt_recall'] = recalls\n",
    "    df['gpt_f1_score'] = f1_scores\n",
    "    df.to_csv(out_df_path, index=False)\n",
    "    print(f\"Metrics calculation completed and saved to {out_df_path}.\")\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
